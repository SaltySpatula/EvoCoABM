{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from Model import Model\n",
    "from GameHistoryAnalysis import GameHistoryAnalysis\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model...\n",
      "Starting Generation: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-6ea6ed995155>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnumber_of_agents\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0magent_computation_capacity\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtokens\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgenerations\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearning_mechanism\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgame\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/FS2021/Agent-based modeling for Business, Economics, Informatics and Social Science/final_project/EvoCoABM/Model.py\u001B[0m in \u001B[0;36mrun_model\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     75\u001B[0m                 \u001B[0;32mfor\u001B[0m \u001B[0magent_jdex\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0magent_index\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumber_of_agents\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     76\u001B[0m                     \u001B[0mone_shot_game\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mGame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0magents\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0magent_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0magents\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0magent_jdex\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgame_type\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 77\u001B[0;31m                     \u001B[0mone_shot_game\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplay\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     78\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlearning_method\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'RL'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     79\u001B[0m                         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0magents\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0magent_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfinal_payoff\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mone_shot_game\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrow_agent_payoff\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/FS2021/Agent-based modeling for Business, Economics, Informatics and Social Science/final_project/EvoCoABM/Model.py\u001B[0m in \u001B[0;36mplay\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    165\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexchange_tokens\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    166\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrow_agent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 167\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumn_agent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    168\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumn_agent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfinal_move\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrow_agent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfinal_move\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    169\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgame_outcome\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrow_agent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfinal_move\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumn_agent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfinal_move\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Desktop/FS2021/Agent-based modeling for Business, Economics, Informatics and Social Science/final_project/EvoCoABM/GeneticAgent.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     33\u001B[0m             \u001B[0maction\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate_actions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0maction\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcommunication_tokens\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 35\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_token\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0maction\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     36\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfinal_move\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0maction\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "number_of_agents = 50\n",
    "generations = 1000\n",
    "game = 'PD'\n",
    "learning_mechanism = 'GA'\n",
    "agent_computation_capacity = 4\n",
    "tokens = 2\n",
    "timeout = 100\n",
    "\n",
    "model = Model(number_of_agents, agent_computation_capacity, tokens, generations, learning_mechanism, timeout, game)\n",
    "model.run_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gha = GameHistoryAnalysis(model.game_history, number_of_agents)\n",
    "gha.plot_average_payoff()\n",
    "gha.plot_average_regular_game_payoff()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gha.plot_total_communication()\n",
    "gha.plot_total_regular_communication()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gha.plot_cooperation_percentage()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gha.plot_average_chat_length()\n",
    "gha.plot_average_regular_chat_length()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gha.plot_number_of_unique_conversations()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gha.plot_NCD_agents()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gha.plot_CRC_agents()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gha.plot_CD_agents()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Investigation into token number relative to cooperative epochs for 1, 2, 3, 4 Tokens, averaged over 20 iterations\n",
    "number_of_agents = 8\n",
    "generations = 10\n",
    "game = 'PD'\n",
    "learning_mechanism = 'GA'\n",
    "agent_computation_capacity = 2\n",
    "tokens = 1\n",
    "timeout = 100\n",
    "\n",
    "iterations = 20\n",
    "states = 8\n",
    "\n",
    "cooperative_epochs_by_state = []\n",
    "avg_percent_outcomes_by_states_by_tokens = []\n",
    "for s in range(states):\n",
    "    cooperative_epochs = [[], [], [], []]\n",
    "    avg_percent_outcomes_by_tokens = []\n",
    "    for t in range(4):\n",
    "        total_coop_epochs = 0\n",
    "        avg_percent_outcomes = [0, 0, 0]\n",
    "        for i in range(iterations):\n",
    "            model = Model(number_of_agents, agent_computation_capacity, t+1, generations, learning_mechanism, timeout, game)\n",
    "            model.run_model()\n",
    "            gha = GameHistoryAnalysis(model.game_history, number_of_agents)\n",
    "            total_coop_epochs += gha.cooperative_epochs\n",
    "\n",
    "            total = sum(gha.outcome_frequency)\n",
    "            percent_outcomes = [(gha.outcome_frequency[m]/total) * 100 for m in range(3)]\n",
    "            avg_percent_outcomes = [avg_percent_outcomes[j] + percent_outcomes[j] for j in range(3)]\n",
    "        avg_percent_outcomes = [avg_percent_outcomes[k]/iterations for k in range(3)]\n",
    "        avg_percent_outcomes_by_tokens.append(avg_percent_outcomes)\n",
    "        cooperative_epochs[t] = (total_coop_epochs/iterations)\n",
    "    avg_percent_outcomes_by_states_by_tokens.append(avg_percent_outcomes_by_tokens)\n",
    "    cooperative_epochs_by_state.append(cooperative_epochs_by_state)\n",
    "\n",
    "for t in range(4):\n",
    "    plt.plot([cooperative_epochs_by_state[p][t] for p in range(states)], label=str(t)+' Tokens')\n",
    "plt.ylabel('Cooperative Epochs / 100 Generations')\n",
    "plt.xlabel('States')\n",
    "plt.show()\n",
    "\n",
    "for t in range(4):\n",
    "    plt.plot([avg_percent_outcomes_by_states_by_tokens[p][t] for p in range(states)] , label=str(t)+' Tokens')\n",
    "plt.ylabel('Game Outcomes / 100 Generations')\n",
    "plt.xlabel('States')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}